#!/bin/bash

# Define HDFS paths for input files
TABLE_LIST_HDFS="/user/name/table_list.txt"
DATES_HDFS="/user/name/dates.txt"

# Local temporary files
TABLE_LIST_LOCAL="/tmp/table_list.txt"
DATES_LOCAL="/tmp/dates.txt"

# Fetch files from HDFS to local
hadoop fs -get ${TABLE_LIST_HDFS} ${TABLE_LIST_LOCAL}
hadoop fs -get ${DATES_HDFS} ${DATES_LOCAL}

# Read each table name from the downloaded table_list.txt
while read -r i; do
  # Read each date from the downloaded dates.txt
  while read -r j; do
    # Create directories in HDFS
    hadoop fs -mkdir -p /tenant/usrf/databases/usrf_core/${i}/cob_date=${j}
    hadoop fs -mkdir -p /tenant/usrf/databases/usrf_core/${i}/cob_date=${j}/CC
    hadoop fs -mkdir -p /tenant/usrf/databases/usrf_core/${i}/cob_date=${j}/CCG
  done < ${DATES_LOCAL}
done < ${TABLE_LIST_LOCAL}

# Cleanup local files
rm -f ${TABLE_LIST_LOCAL} ${DATES_LOCAL}

echo "HDFS directories creation completed!"
