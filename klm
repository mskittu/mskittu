
#!/bin/bash

# Athena configuration
DATABASE="your_database"
OUTPUT_S3_BUCKET="s3://your-bucket/athena-results"
FINAL_OUTPUT_FILE="final_results.csv"

# Define streams and their tables/queries
declare -A STREAM_TABLES
STREAM_TABLES["challenger"]="table1 table2 table3 table4 table5 table6"
STREAM_TABLES["cecl"]="table7"

# Queries to run
declare -A TABLE_QUERIES
TABLE_QUERIES["table1"]="SELECT * FROM table1 LIMIT 10;"
TABLE_QUERIES["table2"]="SELECT * FROM table2 WHERE column1 > 100;"
TABLE_QUERIES["table3"]="SELECT COUNT(*) FROM table3;"
TABLE_QUERIES["table4"]="SELECT * FROM table4 WHERE condition;"
TABLE_QUERIES["table5"]="SELECT column1, column2 FROM table5;"
TABLE_QUERIES["table6"]="SELECT DISTINCT column3 FROM table6;"
TABLE_QUERIES["table7"]="SELECT * FROM table7 WHERE filter_column = 'value';"

# Temporary result file for appending query results
TEMP_FILE="temp_results.csv"

# Ensure temp file and final file are empty
> $TEMP_FILE
> $FINAL_OUTPUT_FILE

# Iterate through streams
for STREAM in "${!STREAM_TABLES[@]}"; do
    echo "Processing stream: $STREAM"
    
    # Iterate through tables in the stream
    for TABLE in ${STREAM_TABLES[$STREAM]}; do
        echo "Processing table: $TABLE"
        
        # Get the query for the table
        QUERY=${TABLE_QUERIES[$TABLE]}
        
        # Run the query in Athena
        QUERY_ID=$(aws athena start-query-execution \
            --query-string "$QUERY" \
            --query-execution-context Database=$DATABASE \
            --result-configuration OutputLocation=$OUTPUT_S3_BUCKET \
            --output text)
        
        echo "Query ID: $QUERY_ID"

        # Wait for the query to complete
        while true; do
            STATUS=$(aws athena get-query-execution --query-execution-id $QUERY_ID --query 'QueryExecution.Status.State' --output text)
            if [[ "$STATUS" == "SUCCEEDED" ]]; then
                break
            elif [[ "$STATUS" == "FAILED" || "$STATUS" == "CANCELLED" ]]; then
                echo "Query failed or cancelled for table $TABLE in stream $STREAM."
                continue
            fi
            sleep 5
        done

        # Download the query result
        RESULT_FILE="$OUTPUT_S3_BUCKET/$QUERY_ID.csv"
        aws s3 cp $RESULT_FILE $TEMP_FILE

        # Append the result to the final output file with metadata
        awk -v stream="$STREAM" -v table="$TABLE" -v query="$QUERY" 'BEGIN {OFS=","} {if (NR == 1 && FNR == 1) print "Stream Name","Table Name","Query","Result"; if (FNR > 1) print stream,table,query,$0}' $TEMP_FILE >> $FINAL_OUTPUT_FILE

        echo "Results appended for table: $TABLE"
    done
done

# Cleanup
rm -f $TEMP_FILE
echo "Final results stored in $FINAL_OUTPUT_FILE"
