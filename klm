# Glue Python Shell job (Python 3.10+ runtime)
# Purpose: Copy S3 objects cross-account from tco8 -> producer with metadata/tags preserved.

import os
import time
import boto3
from botocore.config import Config
from botocore.exceptions import ClientError, EndpointConnectionError
from boto3.s3.transfer import TransferConfig

# ==========================
# ==== USER CONFIG HERE ====
# ==========================
# Source (tco8 account)
SRC_BUCKET = "tco8-source-bucket-name"
SRC_PREFIX = "path/in/source/"          # use "" for whole bucket; must end with "/" if used

# Destination (producer account)
DST_BUCKET = "producer-destination-bucket"
DST_PREFIX = "landing/path/"            # "" allowed; must end with "/" if used

# Cross-account: assume a role in the tco8 account to READ source.
# Leave blank to use current credentials if you already have access.
SRC_ROLE_ARN = "arn:aws:iam::123456789012:role/GlueReadFromTCO8"  # <-- put tco8 role here or "" to skip
SRC_ROLE_SESSION_NAME = "glue-s3-copy-src"

# Destination encryption (optional)
USE_SSE_KMS = False
DST_KMS_KEY_ID = ""                     # e.g., "arn:aws:kms:ap-south-1:111111111111:key/xxxx-...."

# Behavior
OVERWRITE = True                        # if False, skip when size & ETag appear same
INCLUDE_SUFFIXES = []                   # e.g., [".csv", ".parquet"]; empty = all
EXCLUDE_SUFFIXES = []                   # e.g., [".tmp", ".crc"]
MAX_CONCURRENCY = 16                    # threads used by multipart copy
MULTIPART_THRESHOLD_MB = 64             # start multipart copies above this size
REGION = os.getenv("AWS_REGION", "ap-south-1")

# ==========================
# ====== END CONFIG ========
# ==========================

def _assume_role(role_arn: str, session_name: str):
    sts = boto3.client("sts", region_name=REGION)
    creds = sts.assume_role(RoleArn=role_arn, RoleSessionName=session_name)["Credentials"]
    return boto3.Session(
        aws_access_key_id=creds["AccessKeyId"],
        aws_secret_access_key=creds["SecretAccessKey"],
        aws_session_token=creds["SessionToken"],
        region_name=REGION,
    )

def _s3_clients():
    base_cfg = Config(retries={"max_attempts": 10, "mode": "adaptive"})
    # Source session (tco8)
    if SRC_ROLE_ARN:
        src_sess = _assume_role(SRC_ROLE_ARN, SRC_ROLE_SESSION_NAME)
    else:
        src_sess = boto3.Session(region_name=REGION)
    # Destination session (producer)
    dst_sess = boto3.Session(region_name=REGION)

    src_s3 = src_sess.client("s3", config=base_cfg)
    dst_s3 = dst_sess.client("s3", config=base_cfg)
    src_s3_ctrl = src_sess.client("s3control", config=base_cfg)
    return src_s3, dst_s3, src_s3_ctrl

def _should_take(key: str) -> bool:
    if INCLUDE_SUFFIXES and not any(key.endswith(suf) for suf in INCLUDE_SUFFIXES):
        return False
    if EXCLUDE_SUFFIXES and any(key.endswith(suf) for suf in EXCLUDE_SUFFIXES):
        return False
    return True

def _rel_key(full_key: str, prefix: str) -> str:
    if not prefix:
        return full_key
    return full_key[len(prefix):] if full_key.startswith(prefix) else full_key

def _dst_key(src_key: str) -> str:
    return f"{DST_PREFIX}{_rel_key(src_key, SRC_PREFIX)}"

def _head_or_none(s3, bucket, key):
    try:
        return s3.head_object(Bucket=bucket, Key=key)
    except ClientError as e:
        if e.response["Error"]["Code"] in ("404", "NotFound", "NoSuchKey"):
            return None
        raise

def _copy_one(src_s3, dst_s3, src_bucket, src_key, dst_bucket, dst_key, transfer_cfg):
    # Build ExtraArgs
    extra = {
        "ACL": "bucket-owner-full-control",
        "MetadataDirective": "COPY",
        "TaggingDirective": "COPY",
    }
    if USE_SSE_KMS and DST_KMS_KEY_ID:
        extra["ServerSideEncryption"] = "aws:kms"
        extra["SSEKMSKeyId"] = DST_KMS_KEY_ID

    copy_source = {"Bucket": src_bucket, "Key": src_key}
    try:
        dst_s3.copy(
            copy_source, dst_bucket, dst_key,
            ExtraArgs=extra,
            Config=transfer_cfg,
        )
        return True, None
    except (ClientError, EndpointConnectionError) as e:
        return False, str(e)

def _same_enough(src_head, dst_head):
    # Compare size & (if present) ETag as a cheap equality proxy
    try:
        if src_head["ContentLength"] != dst_head["ContentLength"]:
            return False
        s_etag = src_head.get("ETag")
        d_etag = dst_head.get("ETag")
        if s_etag and d_etag and s_etag == d_etag:
            return True
    except KeyError:
        pass
    # If sizes equal but ETag differs (e.g., multipart), treat as equal only if not overwriting
    return src_head.get("ContentLength") == dst_head.get("ContentLength")

def main():
    start_ts = time.time()
    src_s3, dst_s3, _ = _s3_clients()

    paginator = src_s3.get_paginator("list_objects_v2")
    kwargs = {"Bucket": SRC_BUCKET}
    if SRC_PREFIX:
        kwargs["Prefix"] = SRC_PREFIX

    transfer_cfg = TransferConfig(
        multipart_threshold=MULTIPART_THRESHOLD_MB * 1024 * 1024,
        max_concurrency=MAX_CONCURRENCY,
        multipart_chunksize=8 * 1024 * 1024,  # 8MB chunks
        use_threads=True,
    )

    total = copied = skipped = failed = 0

    for page in paginator.paginate(**kwargs):
        for obj in page.get("Contents", []):
            key = obj["Key"]
            if key.endswith("/") or not _should_take(key):
                continue

            total += 1
            dst_key = _dst_key(key)

            # Cheap skip check if OVERWRITE is False
            if not OVERWRITE:
                src_head = _head_or_none(src_s3, SRC_BUCKET, key)
                dst_head = _head_or_none(dst_s3, DST_BUCKET, dst_key)
                if src_head and dst_head and _same_enough(src_head, dst_head):
                    print(f"[SKIP] {key} -> {dst_key} (unchanged)")
                    skipped += 1
                    continue

            ok, err = _copy_one(src_s3, dst_s3, SRC_BUCKET, key, DST_BUCKET, dst_key, transfer_cfg)
            if ok:
                print(f"[OK]   {key} -> {dst_key}")
                copied += 1
            else:
                print(f"[FAIL] {key} -> {dst_key} :: {err}")
                failed += 1

    dur = time.time() - start_ts
    print("========== SUMMARY ==========")
    print(f"Total seen   : {total}")
    print(f"Copied       : {copied}")
    print(f"Skipped      : {skipped}")
    print(f"Failed       : {failed}")
    print(f"Duration (s) : {int(dur)}")

if __name__ == "__main__":
    main()
