import os
import pandas as pd
import cx_Oracle
import subprocess


def fetch_pcds_data():
    """
    Fetches data from Oracle PCDS and saves it to a CSV file.
    """
    try:
        output_path = "/apps/tenant_local/usrf_stg/HadoopSandbox/x01532741/stage/barclays/finance/SOX_FILES/pcds_data.csv"

        # Oracle connection details
        db_name = "CDS"
        user_var = f"USERNAME_{db_name}"
        passwd_var = f"PWD_{db_name}"
        service_var = f"CONNECT_STRING_{db_name}"
        user_name = os.environ.get(user_var)
        passwd = os.environ.get(passwd_var)
        service_nm = os.environ.get(service_var)

        if not all([user_name, passwd, service_nm]):
            raise ValueError("Oracle environment variables are not set.")

        # Parse the service string
        service_nm = service_nm.split('@')[-1]
        host, port_service = service_nm.split(':', 1)
        port, service_nm = port_service.split('/')

        # Create a DSN
        dsn = cx_Oracle.makedsn(host, port, service_name=service_nm)

        # Establish a connection
        connection = cx_Oracle.connect(user=user_name, password=passwd, dsn=dsn)
        cursor = connection.cursor()

        # PCDS Query
        pcds_query = """
        SELECT EXTNL_ACCT_ID, PAST_DUE_151_180_AMT
        FROM dmt_asp_dba.asp_eom_acct_sum
        WHERE ROWNUM <= 1000
        """
        cursor.execute(pcds_query)
        pcds_rows = cursor.fetchall()
        pcds_columns = [desc[0] for desc in cursor.description]
        pcds_df = pd.DataFrame(pcds_rows, columns=pcds_columns)

        cursor.close()
        connection.close()

        if pcds_df.empty:
            raise ValueError("PCDS query returned no data.")

        # Save to CSV
        pcds_df.to_csv(output_path, index=False)
        print(f"✅ PCDS data saved to {output_path}")

        return pcds_df

    except cx_Oracle.DatabaseError as e:
        print(f"❌ Database error while fetching data from PCDS: {e}")
        raise
    except Exception as e:
        print(f"❌ General error while fetching data from PCDS: {e}")
        raise


def fetch_hive_intermediate_data():
    """
    Fetches data from Hive and saves it to a CSV file.
    """
    try:
        output_path = "/apps/tenant_local/usrf_stg/HadoopSandbox/x01532741/stage/barclays/finance/SOX_FILES/hive_intermediate_data.csv"

        # Hive intermediate query
        hive_query = """
        SELECT p4.extnl_acct_id, p4.rtl_trd_tot_cnt AS cbv106_rtnmtot
        FROM usrf_ingest.appl_anlys_mixed_fact p4
        """

        # Execute Hive query and capture output
        hive_command = f"hive -e \"set hive.cli.print.header=true; {hive_query}\""
        result = subprocess.run(
            hive_command, shell=True, check=True,
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True
        )

        # Process Hive query output
        lines = result.stdout.strip().split('\n')
        if not lines or len(lines) < 2:
            raise ValueError("Hive query returned no data or missing header.")

        # Extract header and data
        columns = lines[0].split('\t')  # First line is the header
        data = [line.split('\t') for line in lines[1:]]  # Remaining lines are data
        hive_df = pd.DataFrame(data, columns=columns)

        # Clean invalid elements
        hive_df = hive_df.dropna()  # Removing any invalid/missing values

        # Save to CSV
        hive_df.to_csv(output_path, index=False)
        print(f"✅ Hive Intermediate data saved to {output_path}")

        return hive_df

    except subprocess.CalledProcessError as e:
        print(f"❌ Error executing Hive query: {e.stderr}")
        raise
    except Exception as e:
        print(f"❌ General error while fetching Hive data: {e}")
        raise


def merge_pcds_hive_intermediate():
    """
    Merges PCDS and Hive Intermediate data and saves it to a final CSV file.
    """
    try:
        output_path = "/apps/tenant_local/usrf_stg/HadoopSandbox/x01532741/stage/barclays/finance/SOX_FILES/final_merged_data.csv"

        # Fetch Data
        pcds_df = fetch_pcds_data()
        hive_intermediate_df = fetch_hive_intermediate_data()

        # Ensure DataFrame consistency before merging
        pcds_df["EXTNL_ACCT_ID"] = pcds_df["EXTNL_ACCT_ID"].astype(str)
        hive_intermediate_df["EXTNL_ACCT_ID"] = hive_intermediate_df["EXTNL_ACCT_ID"].astype(str)

        # Merge Data (Outer Join to Keep All Data)
        merged_df = pd.merge(pcds_df, hive_intermediate_df, on="EXTNL_ACCT_ID", how="outer")

        # Ensure the final merged dataframe has the required columns
        expected_columns = ["EXTNL_ACCT_ID", "PAST_DUE_151_180_AMT", "cbv106_rtnmtot"]
        for col in expected_columns:
            if col not in merged_df.columns:
                merged_df[col] = None  # Fill missing columns with None

        # Reorder columns
        merged_df = merged_df[expected_columns]

        # Save merged data to final CSV
        merged_df.to_csv(output_path, index=False)

        print(f"✅ Final merged PCDS and Hive Intermediate data saved to {output_path}")
        return output_path

    except FileNotFoundError as e:
        print(f"❌ File not found during merging: {e}")
        raise
    except pd.errors.MergeError as e:
        print(f"❌ Error merging DataFrames: {e}")
        raise
    except Exception as e:
        print(f"❌ General error merging PCDS and Hive data: {e}")
        raise


# Example usage
if __name__ == "__main__":
    merge_pcds_hive_intermediate()
