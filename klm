import pandas as pd

def compare_and_generate_report(pcds_data_path, hive_data_path, report_path):
    try:
        # Read PCDS and Hive data directly using Pandas
        pcds_df = pd.read_csv(pcds_data_path)
        hive_df = pd.read_csv(hive_data_path)

        # Ensure ACCT_BID and EXTRNL_ACCT_ID have the same data type
        pcds_df["ACCT_BID"] = pcds_df["ACCT_BID"].astype(str)
        hive_df["EXTRNL_ACCT_ID"] = hive_df["EXTRNL_ACCT_ID"].astype(str)

        # Find common columns for comparison
        common_columns = list(set(pcds_df.columns).intersection(hive_df.columns))
        common_columns.remove("ACCT_BID")  # Exclude key columns if needed
        common_columns.remove("EXTRNL_ACCT_ID")  # Exclude key columns if needed

        # Dynamically rename columns with _src and _tgt suffixes
        pcds_renamed = {col: f"{col}_src" for col in common_columns}
        hive_renamed = {col: f"{col}_tgt" for col in common_columns}

        # Merge and compare data
        merged_df = pd.merge(
            pcds_df.rename(columns=pcds_renamed),
            hive_df.rename(columns=hive_renamed),
            left_on="ACCT_BID", right_on="EXTRNL_ACCT_ID",
            how="outer"
        )

        # Add status columns for each common column
        for column in common_columns:
            src_col = f"{column}_src"
            tgt_col = f"{column}_tgt"

            # Compare values
            merged_df[f"{column}_status"] = merged_df.apply(
                lambda row: "PASS" if row[src_col] == row[tgt_col] else "FAILED", axis=1
            )

        # Save the final report with required columns
        final_report_df = merged_df[["EXTRNL_ACCT_ID"] + 
                                    [col for col in merged_df.columns if col.endswith("_status")]].fillna("")
        final_report_df.to_csv(report_path, index=False)
        print(f"Final PPNR Accuracy Report saved to {report_path}")

    except Exception as e:
        print(f"Error generating accuracy report: {e}")
        raise

# Main Execution
base_path = "/apps/tenant_local/usrf_stg/HadoopSandbox/x01532741/job/fin_recon"

try:
    # Commented out the data fetching steps since data already exists
    # Fetch PCDS Data and Save to Local Path
    # fetch_pcds_data(
    #     ["PAST_DUE_151_180_AMT"],
    #     "asp_eom_acct_sum",
    #     f"{base_path}/pcds_data.csv"
    # )

    # Fetch Hive Data and Save to Local Path
    # fetch_hive_data(f"{base_path}/hive_data.csv")

    # Clean Hive Data
    # clean_hive_data(f"{base_path}/hive_data.csv")

    # Compare Data and Generate Report
    compare_and_generate_report(
        f"{base_path}/pcds_data.csv",
        f"{base_path}/hive_data.csv",
        f"{base_path}/ppnr_accuracy_report.csv"
    )

    print(f"Final PPNR Accuracy Report saved to {base_path}/ppnr_accuracy_report.csv")

except Exception as e:
    print(f"Error during execution: {e}")
