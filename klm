#!/bin/bash

# Athena configuration
DATABASE="your_database"
OUTPUT_S3_BUCKET="s3://your-bucket/athena-results"
FINAL_OUTPUT_FILE="final_results.csv"

# Define streams, modules, and their queries
STREAMS=("challanger" "cecl")
CHALLANGER_MODULES="ifrs_pre_default stage airb ipe_default default_book mrd_fact"
CECL_MODULES="module_x"

# Define module queries
MODULE_QUERIES=(
    "ifrs_pre_default:SELECT * FROM ifrs_pre_default LIMIT 10;"
    "stage:SELECT * FROM stage WHERE column1 = 'value';"
    "airb:SELECT COUNT(*) FROM airb;"
    "ipe_default:SELECT * FROM ipe_default WHERE condition = true;"
    "default_book:SELECT DISTINCT column1 FROM default_book;"
    "mrd_fact:SELECT * FROM mrd_fact LIMIT 20;"
    "module_x:SELECT * FROM module_x WHERE filter_column = 'value';"
)

# Temporary file to store query results before appending to final output
TEMP_FILE="temp_results.csv"

# Initialize the final CSV file
echo "Project Name,Stream Name,Module Name,Query,Result" > $FINAL_OUTPUT_FILE

# Helper function to get query for a module
get_query_for_module() {
    local module_name=$1
    for query_entry in "${MODULE_QUERIES[@]}"; do
        local module=$(echo $query_entry | cut -d':' -f1)
        local query=$(echo $query_entry | cut -d':' -f2-)
        if [[ "$module_name" == "$module" ]]; then
            echo "$query"
            return
        fi
    done
    echo ""
}

# Iterate over streams
for STREAM in "${STREAMS[@]}"; do
    echo "Processing stream: $STREAM"
    
    # Get modules for the stream
    if [[ "$STREAM" == "challanger" ]]; then
        MODULES=$CHALLANGER_MODULES
    elif [[ "$STREAM" == "cecl" ]]; then
        MODULES=$CECL_MODULES
    fi

    # Iterate over modules in the stream
    for MODULE in $MODULES; do
        echo "Processing module: $MODULE"
        
        # Get the query for the module
        QUERY=$(get_query_for_module "$MODULE")
        if [[ -z "$QUERY" ]]; then
            echo "No query found for module: $MODULE"
            continue
        fi
        
        # Run the query in Athena
        QUERY_ID=$(aws athena start-query-execution \
            --query-string "$QUERY" \
            --query-execution-context Database=$DATABASE \
            --result-configuration OutputLocation=$OUTPUT_S3_BUCKET \
            --output text)
        
        echo "Query ID: $QUERY_ID"

        # Wait for the query to complete
        while true; do
            STATUS=$(aws athena get-query-execution --query-execution-id $QUERY_ID --query 'QueryExecution.Status.State' --output text)
            if [[ "$STATUS" == "SUCCEEDED" ]]; then
                break
            elif [[ "$STATUS" == "FAILED" || "$STATUS" == "CANCELLED" ]]; then
                echo "Query failed or cancelled for module $MODULE in stream $STREAM."
                continue
            fi
            sleep 5
        done

        # Download the query result
        RESULT_FILE="$OUTPUT_S3_BUCKET/$QUERY_ID.csv"
        aws s3 cp $RESULT_FILE $TEMP_FILE

        # Append the result to the final output file
        if [[ -f $TEMP_FILE ]]; then
            awk -v project="Project_Name" -v stream="$STREAM" -v module="$MODULE" -v query="$QUERY" 'NR > 1 {print project, stream, module, query, $0}' OFS="," $TEMP_FILE >> $FINAL_OUTPUT_FILE
            echo "Results appended for module: $MODULE"
        else
            echo "No results for module: $MODULE"
        fi
    done
done

# Upload the final output file to S3
aws s3 cp $FINAL_OUTPUT_FILE $OUTPUT_S3_BUCKET/$FINAL_OUTPUT_FILE
echo "Final results saved to $OUTPUT_S3_BUCKET/$FINAL_OUTPUT_FILE"
