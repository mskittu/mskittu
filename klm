import sys
import boto3
import pandas as pd
from awsglue.utils import getResolvedOptions

# Get arguments from ksh script
args = getResolvedOptions(sys.argv, ['streamName', 'tablePaths'])
stream_name = args['streamName']
table_paths = args['tablePaths'].split(',')  # Convert the comma-separated paths into a list

s3_client = boto3.client('s3')

# Create an Excel file in memory
excel_writer = pd.ExcelWriter(f'/tmp/{stream_name}_final.xlsx', engine='xlsxwriter')

# Process each CSV file
for table_path in table_paths:
    parts = table_path.replace("s3://", "/").split("/")
    bucket_name = parts[0]
    print("bucket_name:", bucket_name)
    key = '/'.join(parts[1:])

    # Download CSV data from S3
    obj = s3_client.get_object(Bucket=bucket_name, Key=key)
    df = pd.read_csv(obj['Body'])

    # Extract table name from CSV file path
    table_name = key.split("/")[-1].replace('.csv', '')

    # Write data to Excel sheet
    df.to_excel(excel_writer, sheet_name=table_name, index=False)

# Save the XLSX file
excel_writer.close()

# Upload XLSX file back to S3
final_xlsx_path = f'Unknown/{stream_name}_final.xlsx'
s3_client.upload_file(f'/tmp/{stream_name}_final.xlsx', bucket_name, final_xlsx_path)
print(f"Excel file uploaded to s3://{bucket_name}/{final_xlsx_path}")
