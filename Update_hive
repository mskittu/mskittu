import subprocess

def get_hive_table_count():
    try:
        # Define the output file path
        output_file = "/apps/tenant/local/usrf/tmp/HadoopSparkJob_x01532741/job/fin_recon/mds_daily_tbl_recon/0.9/source/target_count.csv"
        
        # Hive command to get counts from tables
        hive_command = (
            "hive -e \"SELECT 'acct_tbal_prcng_b_eoc_fact', COUNT(*) FROM usrf.ingest.cds_acct_tbal_prcng_b_eoc_fact "
            "UNION ALL SELECT 'acct_tbal_prcng_c_eoc_fact', COUNT(*) FROM usrf.ingest.cds_acct_tbal_prcng_c_eoc_fact\" "
            f"> {output_file}"
        )
        
        # Execute the Hive command
        subprocess.run(hive_command, shell=True, check=True)
        
        # Add headers to the output file
        with open(output_file, 'r') as file:
            lines = file.readlines()
        
        with open(output_file, 'w') as file:
            # Write the header
            file.write("Hive_Table_Name,Count\n")
            # Write the original content
            file.writelines(lines)
        
        print(f"Output file with headers created at: {output_file}")
        return output_file

    except subprocess.CalledProcessError as e:
        print("There was an error executing the Hive query:", e)
        return None

# Call the function
get_hive_table_count()
