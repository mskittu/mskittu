import boto3
import pandas as pd
from io import StringIO

def merge_csv_files(source_bucket, target_bucket, source_files, target_file):
    # Initialize the S3 client
    s3 = boto3.client('s3')

    # List to store dataframes
    dataframes = []

    # Read CSV files from source bucket
    for file_name in source_files:
        obj = s3.get_object(Bucket=source_bucket, Key=file_name)
        df = pd.read_csv(obj['Body'])
        dataframes.append(df)

    # Merge all dataframes into a single dataframe
    merged_df = pd.concat(dataframes, ignore_index=True)

    # Convert the merged dataframe to CSV
    csv_buffer = StringIO()
    merged_df.to_csv(csv_buffer, index=False)

    # Upload the merged CSV to the target bucket
    s3.put_object(Bucket=target_bucket, Key=target_file, Body=csv_buffer.getvalue())
    print(f"File successfully written to {target_bucket}/{target_file}")

# Configuration
source_bucket = "s3-jde-epm-testvk"
target_bucket = "s3-jde-epm-testvk-maergfiles"
source_files = ["file1.csv", "file2.csv", "file3.csv"]  # Replace with actual file names
target_file = "merged_file.csv"

# Execute the function
merge_csv_files(source_bucket, target_bucket, source_files, target_file)
